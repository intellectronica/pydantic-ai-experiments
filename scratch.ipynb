{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv 'pydantic-ai[logfire]'\n",
    "from IPython.display import clear_output ; clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logfire\n",
    "_ = logfire.configure(console=False)\n",
    "_ = logfire.instrument_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from textwrap import dedent\n",
    "from typing import List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, CallContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. QUESTION: Is it a living thing?\n",
      "ANSWER: yes\n",
      "\n"
     ]
    },
    {
     "ename": "UnexpectedModelBehavior",
     "evalue": "Exceeded maximum retries (1) for result validation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/_result.py:189\u001b[0m, in \u001b[0;36mResultTool.validate\u001b[0;34m(self, tool_call, allow_partial, wrap_validation_errors)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_call\u001b[38;5;241m.\u001b[39margs, messages\u001b[38;5;241m.\u001b[39mArgsJson):\n\u001b[0;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_call\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_json\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperimental_allow_partial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyd_allow_partial\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/type_adapter.py:425\u001b[0m, in \u001b[0;36mTypeAdapter.validate_json\u001b[0;34m(self, data, strict, context, experimental_allow_partial)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03mValidate a JSON string or bytes against the model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    The validated object.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperimental_allow_partial\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Question\nreflection\n  Field required [type=missing, input_value={'_': {'reflection': \"The...n': 'Is it an animal?'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nquestion\n  Field required [type=missing, input_value={'_': {'reflection': \"The...n': 'Is it an animal?'}}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mToolRetryError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/agent.py:654\u001b[0m, in \u001b[0;36mAgent._handle_model_response\u001b[0;34m(self, model_response, deps)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[43mresult_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_result(result_data, deps, call)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/_result.py:203\u001b[0m, in \u001b[0;36mResultTool.validate\u001b[0;34m(self, tool_call, allow_partial, wrap_validation_errors)\u001b[0m\n\u001b[1;32m    198\u001b[0m     m \u001b[38;5;241m=\u001b[39m messages\u001b[38;5;241m.\u001b[39mRetryPrompt(\n\u001b[1;32m    199\u001b[0m         tool_name\u001b[38;5;241m=\u001b[39mtool_call\u001b[38;5;241m.\u001b[39mtool_name,\n\u001b[1;32m    200\u001b[0m         content\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39merrors(include_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    201\u001b[0m         tool_id\u001b[38;5;241m=\u001b[39mtool_call\u001b[38;5;241m.\u001b[39mtool_id,\n\u001b[1;32m    202\u001b[0m     )\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ToolRetryError(m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mToolRetryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedModelBehavior\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m             turns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(turns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. QUESTION: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mANSWER: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m \u001b[43mtwenty_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma cat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 48\u001b[0m, in \u001b[0;36mtwenty_questions\u001b[0;34m(mytery_object)\u001b[0m\n\u001b[1;32m     46\u001b[0m turns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[43masking_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAsk the next question\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturns\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mquestion\n\u001b[1;32m     49\u001b[0m     answer \u001b[38;5;241m=\u001b[39m ansering_agent\u001b[38;5;241m.\u001b[39mrun_sync(question, deps\u001b[38;5;241m=\u001b[39mmytery_object)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39manswer\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;241m==\u001b[39m Answer\u001b[38;5;241m.\u001b[39mYOU_WIN:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/agent.py:220\u001b[0m, in \u001b[0;36mAgent.run_sync\u001b[0;34m(self, user_prompt, message_history, model, deps)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_sync\u001b[39m(\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    201\u001b[0m     user_prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     deps: AgentDeps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m result\u001b[38;5;241m.\u001b[39mRunResult[ResultData]:\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the agent with a user prompt synchronously.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    This is a convenience method that wraps `self.run` with `asyncio.run()`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m        The result of the run.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/asyncio/futures.py:203\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/asyncio/tasks.py:314\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/agent.py:181\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, user_prompt, message_history, model, deps)\u001b[0m\n\u001b[1;32m    178\u001b[0m cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m request_cost\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _logfire\u001b[38;5;241m.\u001b[39mspan(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhandle model response\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle_span:\n\u001b[0;32m--> 181\u001b[0m     either \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_model_response(model_response, deps)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(either, _MarkFinalResult):\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;66;03m# we have a final result, end the conversation\u001b[39;00m\n\u001b[1;32m    185\u001b[0m         result_data \u001b[38;5;241m=\u001b[39m either\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/agent.py:657\u001b[0m, in \u001b[0;36mAgent._handle_model_response\u001b[0;34m(self, model_response, deps)\u001b[0m\n\u001b[1;32m    655\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_result(result_data, deps, call)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _result\u001b[38;5;241m.\u001b[39mToolRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_incr_result_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [e\u001b[38;5;241m.\u001b[39mtool_retry]\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic_ai/agent.py:751\u001b[0m, in \u001b[0;36mAgent._incr_result_retry\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_result_retry \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_result_retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_result_retries:\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedModelBehavior(\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExceeded maximum retries (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_result_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) for result validation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    753\u001b[0m     )\n",
      "\u001b[0;31mUnexpectedModelBehavior\u001b[0m: Exceeded maximum retries (1) for result validation"
     ]
    }
   ],
   "source": [
    "class Question(BaseModel):\n",
    "    reflection: str = Field(..., description='Considering the questions and answers so far, what are things we can ask next?')\n",
    "    question: str = Field(..., description='The question to ask the other player')\n",
    "\n",
    "asking_agent = Agent('openai:gpt-4o', result_type=Question)\n",
    "\n",
    "@asking_agent.system_prompt  \n",
    "async def asking_agent_system_prompt(ctx: CallContext[List]) -> str:\n",
    "    turns = ctx.deps\n",
    "    prompt = dedent(f\"\"\"\n",
    "        You are playing a game of 20 questions.\n",
    "        You are trying to guess the object the other player is thinking of.\n",
    "        In each turn, you can ask a yes or no question.\n",
    "        The other player will answer with \"yes\", \"no\".\n",
    "    \"\"\").strip()\n",
    "    if len(turns) > 0:\n",
    "        prompt += f\"\\nHere are the questions you have asked so far and the answers you have received:\\n\"\n",
    "        prompt += '\\n'.join([' * ' + turn for turn in turns])\n",
    "    return prompt\n",
    "\n",
    "class Answer(str, Enum):\n",
    "    YES = 'yes'\n",
    "    NO = 'no'\n",
    "    YOU_WIN = 'you win'\n",
    "\n",
    "class AnswerResponse(BaseModel):\n",
    "    reflection: str = Field(..., description=(\n",
    "        'Considering the question, what is the answer? '\n",
    "        'Is it \"yes\" or \"no\"? Or did they guess the '\n",
    "        'object and the answer is \"you win\"?'))\n",
    "    answer: Answer = Field(..., description='The answer to the question - \"yes\", \"no\", or \"you win\"')\n",
    "\n",
    "ansering_agent = Agent('openai:gpt-4o', result_type=AnswerResponse)\n",
    "\n",
    "@ansering_agent.system_prompt\n",
    "async def answering_agent_system_prompt(ctx: CallContext[str]) -> str:\n",
    "    prompt = dedent(f\"\"\"\n",
    "        You are playing a game of 20 questions.\n",
    "        The other player is trying to guess the object you are thinking of.\n",
    "        The object you are thinking of is: {ctx.deps}.\n",
    "        Answer with \"yes\" or \"no\", or \"you win\" if the other player has guessed the object.\n",
    "    \"\"\").strip()\n",
    "    return prompt\n",
    "\n",
    "def twenty_questions(mytery_object):\n",
    "    turns = []\n",
    "    while True:\n",
    "        question = asking_agent.run_sync('Ask the next question', deps=turns).data.question\n",
    "        answer = ansering_agent.run_sync(question, deps=mytery_object).data.answer.value\n",
    "        if answer == Answer.YOU_WIN:\n",
    "            print('You Win!')\n",
    "            break\n",
    "        elif len(turns) >= 20:\n",
    "            print('You Lose!')\n",
    "            break\n",
    "        else:\n",
    "            turns.append(f'{question} - {answer}')\n",
    "            print(f'{len(turns)}. QUESTION: {question}\\nANSWER: {answer}\\n')\n",
    "\n",
    "twenty_questions('a cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
